# Train the agent
#from stable_baselines3.common.env_util import make_vec_env
from stable_baselines3.common.callbacks import EvalCallback
from stable_baselines3.common.callbacks import CheckpointCallback

# Separate evaluation env
env = GoLeftEnv(grid_size=10)

# Use deterministic actions for evaluation
checkpoint_callback = CheckpointCallback(save_freq=10000, save_path="./logs/")


# Train the agent

config = {
    "policy": 'MlpPolicy',
    "total_timesteps": 300000
}

wandb.init(
    config=config,
    sync_tensorboard=True,  # automatically upload SB3's tensorboard metrics to W&B
    project="urforall",
    save_code=True,
)

model = PPO(config['policy'], env, verbose=1, tensorboard_log=f"runs/pponew")
model.learn(
    total_timesteps=config["total_timesteps"],
    callback=[checkpoint_callback, WandbCallback(
        gradient_save_freq=100,
        model_save_path=f"models/{1234}",
        verbose=2,
    )],
)

wandb.finish()
