{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alian3785/game-of-ur/blob/main/%D0%A3%D1%80%20%D0%B4%D0%BB%D1%8F%20%D0%B2%D1%81%D0%B5%D1%85%202.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoxOjIlOImwx"
      },
      "source": [
        "# Stable Baselines Tutorial - Creating a custom Gym environment\n",
        "\n",
        "Github repo: https://github.com/araffin/rl-tutorial-jnrr19\n",
        "\n",
        "Stable-Baselines: https://github.com/hill-a/stable-baselines\n",
        "\n",
        "Documentation: https://stable-baselines.readthedocs.io/en/master/\n",
        "\n",
        "RL Baselines zoo: https://github.com/araffin/rl-baselines-zoo\n",
        "\n",
        "\n",
        "## Introduction\n",
        "\n",
        "In this notebook, you will learn how to use your own environment following the OpenAI Gym interface.\n",
        "Once it is done, you can easily use any compatible (depending on the action space) RL algorithm from Stable Baselines on that environment.\n",
        "\n",
        "## Install Dependencies and Stable Baselines Using Pip\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sp8rSS4DIhEV"
      },
      "outputs": [],
      "source": [
        "# Stable Baselines only supports tensorflow 1.x for now\n",
        "\n",
        "!pip install \"stable-baselines3[extra]>=2.0.0a4\"\n",
        "!pip install sb3-contrib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzevZcgmJmhi"
      },
      "source": [
        "## First steps with the gym interface\n",
        "\n",
        "As you have noticed in the previous notebooks, an environment that follows the gym interface is quite simple to use.\n",
        "It provides to this user mainly three methods:\n",
        "- `reset()` called at the beginning of an episode, it returns an observation\n",
        "- `step(action)` called to take an action with the environment, it returns the next observation, the immediate reward, whether the episode is over and additional information\n",
        "- (Optional) `render(method='human')` which allow to visualize the agent in action. Note that graphical interface does not work on google colab, so we cannot use it directly (we have to rely on `method='rbg_array'` to retrieve an image of the scene\n",
        "\n",
        "Under the hood, it also contains two useful properties:\n",
        "- `observation_space` which one of the gym spaces (`Discrete`, `Box`, ...) and describe the type and shape of the observation\n",
        "- `action_space` which is also a gym space object that describes the action space, so the type of action that can be taken\n",
        "\n",
        "The best way to learn about gym spaces is to look at the [source code](https://github.com/openai/gym/tree/master/gym/spaces), but you need to know at least the main ones:\n",
        "- `gym.spaces.Box`: A (possibly unbounded) box in $R^n$. Specifically, a Box represents the Cartesian product of n closed intervals. Each interval has the form of one of [a, b], (-oo, b], [a, oo), or (-oo, oo). Example: A 1D-Vector or an image observation can be described with the Box space.\n",
        "```python\n",
        "# Example for using image as input:\n",
        "observation_space = spaces.Box(low=0, high=255, shape=(HEIGHT, WIDTH, N_CHANNELS), dtype=np.uint8)\n",
        "```                                       \n",
        "\n",
        "- `gym.spaces.Discrete`: A discrete space in $\\{ 0, 1, \\dots, n-1 \\}$\n",
        "  Example: if you have two actions (\"left\" and \"right\") you can represent your action space using `Discrete(2)`, the first action will be 0 and the second 1.\n",
        "\n",
        "\n",
        "\n",
        "[Documentation on custom env](https://stable-baselines.readthedocs.io/en/master/guide/custom_env.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I98IKKyNJl6K"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "\n",
        "env = gym.make(\"CartPole-v1\")\n",
        "\n",
        "# Box(4,) means that it is a Vector with 4 components\n",
        "print(\"Observation space:\", env.observation_space)\n",
        "print(\"Shape:\", env.observation_space.shape)\n",
        "# Discrete(2) means that there is two discrete actions\n",
        "print(\"Action space:\", env.action_space)\n",
        "\n",
        "# The reset method is called at the beginning of an episode\n",
        "obs = env.reset()\n",
        "# Sample a random action\n",
        "action = env.action_space.sample()\n",
        "print(\"Sampled action:\", action)\n",
        "obs, reward, done, info = env.step(action)\n",
        "# Note the obs is a numpy array\n",
        "# info is an empty dict for now but can contain any debugging info\n",
        "# reward is a scalar\n",
        "print(obs.shape, reward, done, info)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqxatIwPOXe_"
      },
      "source": [
        "##  Gym env skeleton\n",
        "\n",
        "In practice this is how a gym environment looks like.\n",
        "Here, we have implemented a simple grid world were the agent must learn to go always left."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYzDXA9vJfz1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "from gym import spaces\n",
        "import random\n",
        "\n",
        "\n",
        "class GoLeftEnv(gym.Env):\n",
        "  \"\"\"\n",
        "  Custom Environment that follows gym interface.\n",
        "  This is a simple env where the agent must learn to go always left. \n",
        "  \"\"\"\n",
        "  # Because of google colab, we cannot implement the GUI ('human' render mode)\n",
        "  metadata = {'render.modes': ['console']}\n",
        "  # Define constants for clearer code\n",
        "  FIRST = 0\n",
        "  SECOND = 1\n",
        "  THIRD = 2\n",
        "  FORTH = 3\n",
        "  FIFTH= 4\n",
        "  SIXTH = 5\n",
        "  SEVENTH = 6\n",
        "\n",
        "  def __init__(self, grid_size=10):\n",
        "    super(GoLeftEnv, self).__init__()\n",
        "\n",
        "    self.fields = [[0, 0, 7, 7,], [1, 0, 0, 0,], [2, 0, 0, 0,], [3, 0, 0, 0,], [4, 1, 0, 0,], [5, 0, 0, 0], [6, 0, 0, 0], [7, 0, 0, 0], [8, 1, 0, 0], [9, 0, 0, 0], [10, 0, 0, 0], [11, 0, 0, 0], [12, 0, 0, 0], \n",
        "                   [13, 0, 0, 0], [14, 1, 0, 0], [15, 0, 0, 0], [0, 0, 0, 0]]\n",
        "\n",
        "    # Define action and observation space\n",
        "    # They must be gym.spaces objects\n",
        "    # Example when using discrete actions, we have two: left and right\n",
        "    n_actions = 7\n",
        "    self.action_space = spaces.Discrete(n_actions)\n",
        "    # The observation will be the coordinate of the agent\n",
        "    # this can be described both by Discrete and Box space\n",
        "    self.observation_space = spaces.Box(low=-100, high=100,\n",
        "                                        shape=(17,4), dtype=np.float32)\n",
        "\n",
        "  def reset(self):\n",
        "    \"\"\"\n",
        "    Important: the observation must be a numpy array\n",
        "    :return: (np.array) \n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize the agent at the right of the grid\n",
        "    self.fields = [[0, 0, 7, 7,], [1, 0, 0, 0,], [2, 0, 0, 0,], [3, 0, 0, 0,], [4, 1, 0, 0,], [5, 0, 0, 0], [6, 0, 0, 0], [7, 0, 0, 0], [8, 1, 0, 0], [9, 0, 0, 0], [10, 0, 0, 0], [11, 0, 0, 0], [12, 0, 0, 0], \n",
        "                   [13, 0, 0, 0], [14, 1, 0, 0], [15, 0, 0, 0], [0, 0, 0, 0]]\n",
        "\n",
        "    # here we convert to float32 to make it more general (in case we want to use continuous actions)\n",
        "    return np.array(self.fields).astype(np.float32)\n",
        "\n",
        "  def step(self, action):\n",
        "\n",
        "     def first():\n",
        "            numberforcycles = 15\n",
        "\n",
        "            balcycle1 = 0\n",
        "\n",
        "            roll = self.fields[16][0]\n",
        "\n",
        "            lst = [0, 1, 2, 3, 4]\n",
        "            weights = [6.25, 25, 37.5, 25, 6.25]\n",
        "            nextroll = random.choices(lst, weights=weights, k=1)\n",
        "            nextroll = nextroll[0]\n",
        "            self.fields[16][0] = nextroll\n",
        "            #print(\"Выпала\" , roll)\n",
        "            arrplayer1 = []\n",
        "            while balcycle1 < numberforcycles:\n",
        "              ballnow = self.fields[balcycle1][2]\n",
        "              ballindex = self.fields[balcycle1][0]\n",
        "          #расположение фишек игрока 1\n",
        "              if ballnow != 0:  \n",
        "               arrplayer1.append(ballindex)\n",
        "              balcycle1 += 1\n",
        "            if self.fields[8][3] == 1:\n",
        "                arrplayer1.append(8)\n",
        "            #print(arrplayer1) \n",
        "\n",
        "            balcycle1 = 0\n",
        "            arrchoice1 = []\n",
        "            while balcycle1 < numberforcycles:\n",
        "              ballnow = self.fields[balcycle1][2]\n",
        "              ballindex = self.fields[balcycle1][0]\n",
        "              if ballnow != 0:  \n",
        "                ballfuture = ballindex + roll\n",
        "                if ballfuture <= numberforcycles:\n",
        "                 if ballfuture not in arrplayer1:\n",
        "                  arrchoice1.append(ballfuture)\n",
        "              # print(\"Выпала\" , self.roll)\n",
        "                  #print(\"текущая позиция\" , ballindex)\n",
        "                  #print(\"возможная позиция\" , ballfuture)   \n",
        "              balcycle1 += 1\n",
        "\n",
        "\n",
        "\n",
        "            if arrchoice1:\n",
        "\n",
        "              #случайный бот:\n",
        "              playeronemove = random.choice(arrchoice1)\n",
        "\n",
        "              #Очень жадный бот:\n",
        "              #playeronemove = len(arrchoice1)\n",
        "              #playeronemove = arrchoice1[playeronemove-1]\n",
        "\n",
        "              #Жадный бот:\n",
        "              #playeronemove = 33\n",
        "              #for arrchoice in arrchoice1:\n",
        "              #  if self.fields[arrchoice][1] == 1 or (self.fields[arrchoice][3] == 1 and self.fields[arrchoice][0] >= 5 and self.fields[arrchoice][0] <= 12):\n",
        "              #    playeronemove = self.fields[arrchoice][0]                \n",
        "              #if playeronemove == 33:    \n",
        "              #  playeronemove = len(arrchoice1)\n",
        "              #  playeronemove = arrchoice1[playeronemove-1]\n",
        "\n",
        "              #playeronemove = random.choice(arrchoice1)\n",
        "              playeronepos = playeronemove - roll\n",
        "              #print(playeronepos)\n",
        "              self.fields[playeronepos][2] = self.fields[playeronepos][2] - 1\n",
        "              self.fields[playeronemove][2] = self.fields[playeronemove][2] + 1\n",
        "              if self.fields[playeronemove][3] == 1 and playeronemove >= 5 and playeronemove <= 12:\n",
        "                self.fields[playeronemove][3] = 0\n",
        "                self.fields[0][3] = self.fields[0][3] + 1\n",
        "                #print(\"мы забрали шашку на\" , self.fields[playeronemove][0])\n",
        "              #print(\"боту выпал\", roll)\n",
        "              #print(\"бот ходит\", playeronemove)\n",
        "              return playeronemove\n",
        "\n",
        "     def second():\n",
        "            numberforcycles = 15\n",
        "\n",
        "            agentroll = self.fields[16][1] \n",
        "\n",
        "            lst = [0, 1, 2, 3, 4]\n",
        "            weights = [6.25, 25, 37.5, 25, 6.25]\n",
        "            nextagentroll = random.choices(lst, weights=weights, k=1)\n",
        "            nextagentroll = nextagentroll[0]\n",
        "            self.fields[16][1] = nextagentroll\n",
        "            #print(\"Агенту Выпал\" , agentroll)\n",
        "\n",
        "            agentcycle = 0\n",
        "            arrplayeragent = []\n",
        "\n",
        "            while agentcycle < numberforcycles:\n",
        "              agentballnow = self.fields[agentcycle][3]\n",
        "              agentballindex = self.fields[agentcycle][0]\n",
        "          #расположение фишек игрока 2\n",
        "              if agentballnow != 0:  \n",
        "               arrplayeragent.append(agentballindex)    \n",
        "              agentcycle += 1\n",
        "            if self.fields[8][2] == 1:\n",
        "                arrplayeragent.append(8)\n",
        "\n",
        "            #print(\"фишки агента\", arrplayeragent) \n",
        "\n",
        "            agentcycle = 0\n",
        "            arrplayeragent2 = []\n",
        "\n",
        "            while agentcycle < numberforcycles:\n",
        "              agentballnow = self.fields[agentcycle][3]\n",
        "              agentballindex = self.fields[agentcycle][0]\n",
        "          #будущее фишек игрока 2\n",
        "              if agentballnow != 0:  \n",
        "               agentballfuture = agentballindex + agentroll  \n",
        "               if agentballfuture <= numberforcycles:\n",
        "                if agentballfuture not in arrplayeragent:\n",
        "                  arrplayeragent2.append(agentballfuture) \n",
        "              agentcycle += 1\n",
        "\n",
        "            #print(arrplayeragent2)\n",
        "\n",
        "            \n",
        "\n",
        "            if arrplayeragent2:\n",
        "              playeragentmove = len(arrplayeragent2)\n",
        "              playeragentmove = arrplayeragent2[0]#arrplayeragent2[playeragentmove-1]\n",
        "\n",
        "              if action == self.FIRST:\n",
        "                if len(arrplayeragent2) > 0:\n",
        "                 playeragentmove = arrplayeragent2[0]\n",
        "                else:\n",
        "                 playeragentmove = playeragentmove\n",
        "              elif action == self.SECOND:\n",
        "               if len(arrplayeragent2) > 1:\n",
        "                playeragentmove = arrplayeragent2[1]\n",
        "               else:\n",
        "                playeragentmove = playeragentmove\n",
        "              elif action == self.THIRD:\n",
        "               if len(arrplayeragent2) > 2:\n",
        "                playeragentmove = arrplayeragent2[2]\n",
        "               else:\n",
        "                playeragentmove = playeragentmove\n",
        "              elif action == self.FORTH:\n",
        "               if len(arrplayeragent2) > 3:\n",
        "                playeragentmove = arrplayeragent2[3]\n",
        "               else:\n",
        "                playeragentmove = playeragentmove\n",
        "              elif action == self.FIFTH:\n",
        "               if len(arrplayeragent2) > 4:\n",
        "                playeragentmove = arrplayeragent2[4]\n",
        "               else:\n",
        "                playeragentmove = playeragentmove\n",
        "              elif action == self.SIXTH:\n",
        "               if len(arrplayeragent2) > 5:\n",
        "                playeragentmove = arrplayeragent2[5]\n",
        "               else:\n",
        "                playeragentmove = playeragentmove\n",
        "              elif action == self.SEVENTH:\n",
        "               if len(arrplayeragent2) > 6:\n",
        "                playeragentmove = arrplayeragent2[6]\n",
        "               else:\n",
        "                playeragentmove = playeragentmove \n",
        "              else:\n",
        "                raise ValueError(\"Received invalid action={} which is not part of the action space\".format(action))\n",
        "\n",
        "\n",
        "\n",
        "              #print(\"Агент делает выбор\", playeragentmove)\n",
        "\n",
        "              #playeragentmove = random.choice(arrplayeragent)\n",
        "              playeragentpos = playeragentmove - agentroll\n",
        "              self.fields[playeragentpos][3] = self.fields[playeragentpos][3] - 1\n",
        "              self.fields[playeragentmove][3] = self.fields[playeragentmove][3] + 1\n",
        "              if self.fields[playeragentmove][2] == 1 and playeragentmove >= 5 and playeragentmove <= 12:\n",
        "                self.fields[playeragentmove][2] = 0\n",
        "                self.fields[0][2] = self.fields[0][2] + 1\n",
        "                #print(\"Агент забрал шашку на\" , self.fields[playeragentmove][0])\n",
        "              #print(\"Агент ходит\" , playeragentmove)\n",
        "              return playeragentmove\n",
        "            else:          \n",
        "              rrr = 0#print(\"Выпал 0 и агент не делает выбора\")\n",
        "     #while True:\n",
        "     # thisbotmove = first()      \n",
        "     # if thisbotmove != 4 or thisbotmove != 8 or thisbotmove != 14:\n",
        "     #    #print(\"нет второго хода бота\")\n",
        "     #    break\n",
        "\n",
        "     if self.fields[16][3] != 1:\n",
        "      thisbotmove = first()\n",
        "      #print(first())\n",
        "      if thisbotmove == 4 or thisbotmove == 8 or thisbotmove == 14:\n",
        "       #print(\"Второй ход бота\", thisbotmove)\n",
        "       self.fields[16][2] = 1\n",
        "      else:\n",
        "       self.fields[16][2] = 0 \n",
        "    # if thisbotmove == 4 or thisbotmove == 8 or thisbotmove == 14:\n",
        "     if self.fields[16][2] != 1:\n",
        "      thisagentmove = second()\n",
        "      #print(second())\n",
        "      if thisagentmove == 4 or thisagentmove == 8 or thisagentmove == 14:\n",
        "        #print(\"Второй ход агента\", thisagentmove)\n",
        "        self.fields[16][3] = 1\n",
        "      else:\n",
        "        self.fields[16][3] = 0 \n",
        "     #while True:\n",
        "     # thisagentmove =  second()\n",
        "     # if thisagentmove != 4 or thisagentmove != 8 or thisagentmove != 14:\n",
        "     #    #print(\"нет второго хода агента\")\n",
        "     #    break\n",
        "\n",
        "\n",
        "     done = bool(self.fields[15][2] >= 7 or self.fields[15][3] >= 7)\n",
        "\n",
        "\n",
        "     reward = 0\n",
        "     if self.fields[15][3] >= 7:\n",
        "       reward = 100\n",
        "\n",
        "    # Optionally we can pass additional info, we are not using that for now\n",
        "     info = {}\n",
        "\n",
        "     return np.array(self.fields).astype(np.float32), reward, done, info\n",
        "\n",
        "\n",
        "  def render(self, mode='console'):\n",
        "    if mode != 'console':\n",
        "      raise NotImplementedError()\n",
        "    # agent is represented as a cross, rest as a dot\n",
        "\n",
        "    #print(self.fields[0])\n",
        "\n",
        "  def close(self):\n",
        "    pass\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJ3khFtkSE0g"
      },
      "source": [
        "### Testing the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i62yf2LvSAYY"
      },
      "outputs": [],
      "source": [
        "iii=0\n",
        "iiia = []\n",
        "while iii < 10:\n",
        " env = GoLeftEnv()\n",
        " obs = env.reset()\n",
        " n_steps = 200\n",
        " for _ in range(n_steps):\n",
        "    # Random action\n",
        "     action = env.action_space.sample()\n",
        "     print(\"Action: \", action)\n",
        "     obs, reward, done, info = env.step(action)\n",
        "     print('obs=', obs, 'reward=', reward, 'done=', done)\n",
        "     print(\"observation space shape:\", env.observation_space.shape)\n",
        "     if obs[4][2] == 1:\n",
        "       print(u\"\\U0001F7E5\", end=\"\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\", end=\"\")\n",
        "     if obs[5][2] == 1:\n",
        "       print(u\"\\U0001F7E5\", end=\"\")\n",
        "     elif obs[5][3] == 1:\n",
        "       print(u\"\\U0001F7E6\", end=\"\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\", end=\"\")\n",
        "     if obs[4][3] == 1:\n",
        "       print(u\"\\U0001F7E6\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\")\n",
        "     if obs[3][2] == 1:\n",
        "       print(u\"\\U0001F7E5\", end=\"\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\", end=\"\")\n",
        "     if obs[6][2] == 1:\n",
        "       print(u\"\\U0001F7E5\", end=\"\")\n",
        "     elif obs[6][3] == 1:\n",
        "       print(u\"\\U0001F7E6\", end=\"\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\", end=\"\")\n",
        "     if obs[3][3] == 1:\n",
        "       print(u\"\\U0001F7E6\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\")\n",
        "     if obs[2][2] == 1:\n",
        "       print(u\"\\U0001F7E5\", end=\"\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\", end=\"\")\n",
        "     if obs[7][2] == 1:\n",
        "       print(u\"\\U0001F7E5\", end=\"\")\n",
        "     elif obs[7][3] == 1:\n",
        "       print(u\"\\U0001F7E6\", end=\"\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\", end=\"\")\n",
        "     if obs[2][3] == 1:\n",
        "       print(u\"\\U0001F7E6\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\")\n",
        "     if obs[1][2] == 1:\n",
        "       print(u\"\\U0001F7E5\", end=\"\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\", end=\"\")\n",
        "     if obs[8][2] == 1:\n",
        "       print(u\"\\U0001F7E5\", end=\"\")\n",
        "     elif obs[8][3] == 1:\n",
        "       print(u\"\\U0001F7E6\", end=\"\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\", end=\"\")\n",
        "     if obs[1][3] == 1:\n",
        "       print(u\"\\U0001F7E6\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\")\n",
        "     print(u\"\\u2B1B\", end=\"\")\n",
        "     if obs[9][2] == 1:\n",
        "       print(u\"\\U0001F7E5\", end=\"\")\n",
        "     elif obs[9][3] == 1:\n",
        "       print(u\"\\U0001F7E6\", end=\"\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\", end=\"\")\n",
        "     print(u\"\\u2B1B\")\n",
        "     print(u\"\\u2B1B\", end=\"\")\n",
        "     if obs[10][2] == 1:\n",
        "       print(u\"\\U0001F7E5\", end=\"\")\n",
        "     elif obs[10][3] == 1:\n",
        "       print(u\"\\U0001F7E6\", end=\"\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\", end=\"\")\n",
        "     print(u\"\\u2B1B\")\n",
        "     if obs[14][2] == 1:\n",
        "       print(u\"\\U0001F7E5\", end=\"\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\", end=\"\")\n",
        "     if obs[11][2] == 1:\n",
        "       print(u\"\\U0001F7E5\", end=\"\")\n",
        "     elif obs[11][3] == 1:\n",
        "       print(u\"\\U0001F7E6\", end=\"\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\", end=\"\")\n",
        "     if obs[14][3] == 1:\n",
        "       print(u\"\\U0001F7E6\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\")\n",
        "     if obs[13][2] == 1:\n",
        "       print(u\"\\U0001F7E5\", end=\"\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\", end=\"\")\n",
        "     if obs[12][2] == 1:\n",
        "       print(u\"\\U0001F7E5\", end=\"\")\n",
        "     elif obs[12][3] == 1:\n",
        "       print(u\"\\U0001F7E6\", end=\"\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\", end=\"\")\n",
        "     if obs[13][3] == 1:\n",
        "       print(u\"\\U0001F7E6\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\")\n",
        "\n",
        "\n",
        "\n",
        "     env.render(mode='console')\n",
        "     if (done == 1):\n",
        "       print(\"Goal reached!\", \"reward=\", reward)\n",
        "       iiia.append(reward)\n",
        "       break\n",
        " iii += 1 \n",
        "print(iiia)\n",
        "win = []\n",
        "notwin = []\n",
        "for iiiaa in iiia:\n",
        "  if iiiaa <= 0:\n",
        "    notwin.append(iiiaa)\n",
        "  elif iiiaa > 0:\n",
        "    win.append(iiiaa)\n",
        "print(win)\n",
        "print(notwin)\n",
        "print(len(win))\n",
        "print(len(notwin))\n",
        "# sample action:\n",
        "print(\"sample action:\", env.action_space.sample())\n",
        "\n",
        "# observation space shape:\n",
        "print(\"observation space shape:\", env.observation_space.shape)\n",
        "\n",
        "# sample observation:\n",
        "print(\"sample observation:\", env.observation_space.sample())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pv1e1qJETfHU"
      },
      "source": [
        "### Try it with Stable-Baselines\n",
        "\n",
        "Once your environment follow the gym interface, it is quite easy to plug in any algorithm from stable-baselines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQfLBE28SNDr"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "#from stable_baselines3.common.cmd_util import make_vec_env\n",
        "\n",
        "# Instantiate the env\n",
        "env = GoLeftEnv(grid_size=10)\n",
        "# wrap it\n",
        "env = make_vec_env(lambda: env, n_envs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRV4Q7FVUKB6"
      },
      "outputs": [],
      "source": [
        "# Train the agent\n",
        "model = PPO('MlpPolicy', env, verbose=1).learn(100000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "PPO_path = os.path.join('Training', 'Saved Models', '5millionppo')\n",
        "model.save(PPO_path)"
      ],
      "metadata": {
        "id": "jzn_0Y-pF1dB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "#evaluate_policy(model, env, n_eval_episodes=1000)\n",
        "#run.finish()\n",
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=100, deterministic=True)\n",
        "\n",
        "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")"
      ],
      "metadata": {
        "id": "hSNW0uDbWekY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iii=0\n",
        "iiia = []\n",
        "while iii < 50:\n",
        " env = GoLeftEnv()\n",
        " obs = env.reset()\n",
        " n_steps = 200\n",
        " for _ in range(n_steps):\n",
        "     action, _ = model.predict(obs, deterministic=True)    \n",
        "     print(\"Action: \", action)\n",
        "     obs, reward, done, info = env.step(action)\n",
        "     print('obs=', obs, 'reward=', reward, 'done=', done)\n",
        "     print(\"observation space shape:\", env.observation_space.shape)\n",
        "     if obs[4][2] == 1:\n",
        "       print(u\"\\U0001F7E5\", end=\"\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\", end=\"\")\n",
        "     if obs[5][2] == 1:\n",
        "       print(u\"\\U0001F7E5\", end=\"\")\n",
        "     elif obs[5][3] == 1:\n",
        "       print(u\"\\U0001F7E6\", end=\"\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\", end=\"\")\n",
        "     if obs[4][3] == 1:\n",
        "       print(u\"\\U0001F7E6\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\")\n",
        "     if obs[3][2] == 1:\n",
        "       print(u\"\\U0001F7E5\", end=\"\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\", end=\"\")\n",
        "     if obs[6][2] == 1:\n",
        "       print(u\"\\U0001F7E5\", end=\"\")\n",
        "     elif obs[6][3] == 1:\n",
        "       print(u\"\\U0001F7E6\", end=\"\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\", end=\"\")\n",
        "     if obs[3][3] == 1:\n",
        "       print(u\"\\U0001F7E6\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\")\n",
        "     if obs[2][2] == 1:\n",
        "       print(u\"\\U0001F7E5\", end=\"\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\", end=\"\")\n",
        "     if obs[7][2] == 1:\n",
        "       print(u\"\\U0001F7E5\", end=\"\")\n",
        "     elif obs[7][3] == 1:\n",
        "       print(u\"\\U0001F7E6\", end=\"\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\", end=\"\")\n",
        "     if obs[2][3] == 1:\n",
        "       print(u\"\\U0001F7E6\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\")\n",
        "     if obs[1][2] == 1:\n",
        "       print(u\"\\U0001F7E5\", end=\"\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\", end=\"\")\n",
        "     if obs[8][2] == 1:\n",
        "       print(u\"\\U0001F7E5\", end=\"\")\n",
        "     elif obs[8][3] == 1:\n",
        "       print(u\"\\U0001F7E6\", end=\"\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\", end=\"\")\n",
        "     if obs[1][3] == 1:\n",
        "       print(u\"\\U0001F7E6\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\")\n",
        "     print(u\"\\u2B1B\", end=\"\")\n",
        "     if obs[9][2] == 1:\n",
        "       print(u\"\\U0001F7E5\", end=\"\")\n",
        "     elif obs[9][3] == 1:\n",
        "       print(u\"\\U0001F7E6\", end=\"\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\", end=\"\")\n",
        "     print(u\"\\u2B1B\")\n",
        "     print(u\"\\u2B1B\", end=\"\")\n",
        "     if obs[10][2] == 1:\n",
        "       print(u\"\\U0001F7E5\", end=\"\")\n",
        "     elif obs[10][3] == 1:\n",
        "       print(u\"\\U0001F7E6\", end=\"\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\", end=\"\")\n",
        "     print(u\"\\u2B1B\")\n",
        "     if obs[14][2] == 1:\n",
        "       print(u\"\\U0001F7E5\", end=\"\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\", end=\"\")\n",
        "     if obs[11][2] == 1:\n",
        "       print(u\"\\U0001F7E5\", end=\"\")\n",
        "     elif obs[11][3] == 1:\n",
        "       print(u\"\\U0001F7E6\", end=\"\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\", end=\"\")\n",
        "     if obs[14][3] == 1:\n",
        "       print(u\"\\U0001F7E6\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\")\n",
        "     if obs[13][2] == 1:\n",
        "       print(u\"\\U0001F7E5\", end=\"\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\", end=\"\")\n",
        "     if obs[12][2] == 1:\n",
        "       print(u\"\\U0001F7E5\", end=\"\")\n",
        "     elif obs[12][3] == 1:\n",
        "       print(u\"\\U0001F7E6\", end=\"\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\", end=\"\")\n",
        "     if obs[13][3] == 1:\n",
        "       print(u\"\\U0001F7E6\")\n",
        "     else:\n",
        "       print(u\"\\u2B1C\")\n",
        "\n",
        "\n",
        "\n",
        "     env.render(mode='console')\n",
        "     if (done == 1):\n",
        "       print(\"Goal reached!\", \"reward=\", reward)\n",
        "       iiia.append(reward)\n",
        "       break\n",
        " iii += 1 \n",
        "print(iiia)\n",
        "win = []\n",
        "notwin = []\n",
        "for iiiaa in iiia:\n",
        "  if iiiaa <= 0:\n",
        "    notwin.append(iiiaa)\n",
        "  elif iiiaa > 0:\n",
        "    win.append(iiiaa)\n",
        "print(win)\n",
        "print(notwin)\n",
        "print(len(win))\n",
        "print(len(notwin))\n",
        "# sample action:\n",
        "print(\"sample action:\", env.action_space.sample())\n",
        "\n",
        "# observation space shape:\n",
        "print(\"observation space shape:\", env.observation_space.shape)\n",
        "\n",
        "# sample observation:\n",
        "print(\"sample observation:\", env.observation_space.sample())"
      ],
      "metadata": {
        "id": "a87DGNWCePkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOggIa9sU--b"
      },
      "source": [
        "## It is your turn now, be creative!\n",
        "\n",
        "As an exercise, that's now your turn to build a custom gym environment.\n",
        "There is no constrain about what to do, be creative! (but not too creative, there is not enough time for that)\n",
        "\n",
        "If you don't have any idea, here is is a list of the environment you can implement:\n",
        "- Transform the discrete grid world to a continuous one, you will need to change a bit the logic and the action space\n",
        "- Create a 2D grid world and add walls\n",
        "- Create a tic-tac-toe game\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBDp4Pm-Uh4D"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}